import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import fetch from 'node-fetch';

const app = express();
app.use(cors());
app.use(express.json());

const MODE = process.env.LLM_BACKEND || 'OLLAMA';
const MODEL = process.env.OLLAMA_MODEL || 'llama3.1';

// ðŸ”¹ MOCK-Ð¾Ñ‚Ð²ÐµÑ‚ (Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹ ÐµÑÐ»Ð¸ Ollama Ð½Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½)
function mockTutor(question) {
    return {
        mode: 'MOCK',
        answer: `ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ: "${question}".`
    };
}

// ðŸ”¹ Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð² Ollama â€” ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚
async function ollamaTutor(question) {
    const prompt = `Ð¢Ñ‹ ÑƒÐ¼Ð½Ñ‹Ð¹ Ð¸ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð°. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¿Ð¾ ÑÑƒÑ‚Ð¸ Ð¸ Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾. Ð’Ð¾Ð¿Ñ€Ð¾Ñ: ${question}`;

    const r = await fetch('http://localhost:11434/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            model: MODEL,
            prompt,
            stream: false
        })
    });

    const data = await r.json();
    return { mode: 'OLLAMA', answer: data.response };
}

// ðŸ”¹ API endpoint
app.post('/api/chat', async (req, res) => {
    const { question } = req.body;
    try {
        if (!question?.trim()) {
            return res.status(400).json({ error: 'Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿ÑƒÑÑ‚Ð¾Ð¹' });
        }

        if (MODE === 'MOCK') {
            return res.json(mockTutor(question));
        } else if (MODE === 'OLLAMA') {
            const ans = await ollamaTutor(question);
            return res.json(ans);
        } else {
            return res.json({ mode: 'UNKNOWN', answer: 'ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼' });
        }
    } catch (e) {
        res.status(500).json({ error: e.toString() });
    }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () =>
    console.log(`Server started: http://localhost:${PORT} â€¢ Mode=${MODE}`)
);
